{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **NFT COLLABOT**\n",
    "\n",
    "> Summary Value Prop Blog\n",
    "\n",
    "*NFT CollaBot* is a project that designed by obtaining requirements of NFT ecosystem. NFT marketplace from Tezos ecosystem named objkt.com will be starting point of the project. NFT CollaBot aims to make underrated artists more visible. Also, targets to perform extensive visual-oriented statistics for NFT Creators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are **two main features** of the NFT CollaBot:\n",
    "> NFT Recommendation by Tag\n",
    "\n",
    "> Stats for NFT Creators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries for data process\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for visualization of the data\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# importing libraries to handle web scraping\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# string operations will be handled during data analysis\n",
    "import re\n",
    "import string\n",
    "from io import StringIO\n",
    "\n",
    "# also using these libraries\n",
    "import random\n",
    "import time\n",
    "\n",
    "# date-related operations exists on the code\n",
    "from datetime import *\n",
    "\n",
    "import math\n",
    "\n",
    "# for error handling\n",
    "import contextlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### API DOCUMENTATION\n",
    "\n",
    "Objktcom has a published API documentation\n",
    "*https://data.objkt.com/docs/#listing*\n",
    "\n",
    "Documentation points GraphiQL explore page to try queries.\n",
    "There is a link below that explains how to write queries with GraphiQL\n",
    "*https://graphql.org/learn/queries/*\n",
    "\n",
    "Besides, there is a useful link to code on Python using GraphiQL queries. Check the following link:\n",
    "*https://towardsdatascience.com/connecting-to-a-graphql-api-using-python-246dda927840*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objktcom api endpoint will be used for several times to evaluate queries\n",
    "\n",
    "api_endpoint = 'https://data.objkt.com/v2/graphql'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to mail from objkt.com, API Endpoint will move to Version 3 after 30 January 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_API_launch_datetime():\n",
    "    new_API_launchTime = date(2023,1,20)    # assign the launch time\n",
    "    current_date=date.today()\n",
    "    if current_date<new_API_launchTime:     # if earlier than the launch time\n",
    "        return api_endpoint\n",
    "    else:\n",
    "        return 'https://data.objkt.com/v3/graphql'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ##### GRAPHIQL\n",
    "GraphiQL playground is useful tool to understand insight of the query format\n",
    ">  https://data.objkt.com/explore/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Retrieve Beginning Primary Key Value\n",
    "\n",
    "There are thousands of NFTs belongs to a tag. It will take too long to get all of the data. Besides, it will be more effective to show newer NFTs to achieve main target of the project.\n",
    "\n",
    "The mechanism have to use token_pk to request data, according to API constrains. Decided to choose a token_pk using a timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query for getting primary key has evaluated below:\n",
    "\n",
    "#initial_token_pk_query=\"\"\"query {\n",
    "#    token(where: {timestamp: {_gt: \"2022-06-15T00:12:00+00:00\"}}, limit: 1) {\n",
    "#    creators {\n",
    "#        token_pk\n",
    "#    }\n",
    "#    }\n",
    "#}\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# send request\n",
    "token_pk_data = requests.post(api_endpoint, json={'query': initial_token_pk_query})\n",
    "token_pk_data = json.loads(token_pk_data.text)\n",
    "token_pk_data=token_pk_data['data']['token']\n",
    "\n",
    "# output is 8682680\n",
    "# this primary key will be used in the next steps of the development\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Feature 01*: NFT Recommendation Mechanism\n",
    "\n",
    "> ### RECURSIVE MECHANISM TO GET TOKEN PRIMARY KEY DATA\n",
    "\n",
    "After getting primary key of the starting point, query for tag of token will be evaluated. In this query, only primary keys of tokens will be requested from API. Then, this primary key value will be used to get information about related NFT. This mechanism aims to implement request process recursively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=[0]      # counts how many times has the function is executed\n",
    "\n",
    "def request_nft_token_pk(tag_name_variable):\n",
    "      # sourcery skip: remove-unnecessary-else, swap-if-else-branches\n",
    "      if counter[0]>0:global pk_value\n",
    "      if counter[0]==0: pk_value=8682680\n",
    "\n",
    "      # declare query to request data from api\n",
    "      nftToken_pk_query=\"\"\"query {\n",
    "      token_tag(where: {tag: {name: {_eq: tag_name_variable}}, _and: {token_pk: {_gt: last_pk_value}}}) {\n",
    "      token_pk\n",
    "      }\n",
    "      }\"\"\"\n",
    "      #create dynamic query to request recursively\n",
    "      nftToken_pk_query=nftToken_pk_query.replace(\"tag_name_variable\",tag_name_variable)\n",
    "      nftToken_pk_query=nftToken_pk_query.replace(\"last_pk_value\",str(pk_value))\n",
    "\n",
    "      #request data from objkt.com api endpoint\n",
    "      token_pk_request = requests.post(api_endpoint, json={'query': nftToken_pk_query})\n",
    "      token_pk_request = json.loads(token_pk_request.text)\n",
    "      token_pk_request=token_pk_request['data']['token_tag']\n",
    "\n",
    "      #have to assign a boolean variable to check is response empty or not\n",
    "      isEmpty_response=False\n",
    "\n",
    "      if counter[0]>0:                       # to avoid unbound local error...\n",
    "            global primaryKey_df             # ...declare as global\n",
    "            global primaryKey_df_loop\n",
    "\n",
    "      if counter[0]==0 :\n",
    "            primaryKey_df = pd.DataFrame()\n",
    "            primaryKey_df_loop = pd.DataFrame()\n",
    "      primaryKey_df_loop = pd.DataFrame(token_pk_request)            # convert json data into a data frame\n",
    "      primaryKey_df=pd.concat([primaryKey_df,primaryKey_df_loop])    # concatenate two data frames to save all data in one data frame\n",
    "\n",
    "\n",
    "      if primaryKey_df_loop.shape[0]>0:         # assign latest primary key value to a new variable to use this value for recursion queries\n",
    "            pk_value=int(primaryKey_df_loop.loc[(primaryKey_df_loop.shape[0])-1].values)\n",
    "      else: isEmpty_response=True               # make boolean value True whenever response is empty\n",
    "\n",
    "      # increase one the variable for each execution of recursive function\n",
    "      counter[0]+=1\n",
    "\n",
    "      # create recursive algorithm inside function\n",
    "      if not isEmpty_response:     # execute the function since it does not retrieve any data from api endpoint\n",
    "            #time.sleep(0.1)\n",
    "            return request_nft_token_pk(tag_name_variable)\n",
    "      else:\n",
    "            primaryKey_df.set_index(np.arange(primaryKey_df.shape[0]))\n",
    "            return primaryKey_df\n",
    "\n",
    "#request_nft_token_pk(\"cartoon\")\n",
    "\n",
    "# note!: arrange index of the data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### How NFT Recommendation Mechanism Works?\n",
    "\n",
    ">> **Random Recommendation**\n",
    "\n",
    "Select an NFT randomly to perform functionality more fair for everyone\n",
    "\n",
    ">> Bonus: **Future Aspects:**\n",
    "\n",
    "On the other hand, this mechanism will be extended with an algorithm in further stages\n",
    "\n",
    "There will be an input option to ask for only one specific marketplace *[e.g. recommand hic et nunc only]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "randomNFT_index=random.sample(range(primaryKey_df.shape[0]),10)\n",
    "randomNFT=primaryKey_df.iloc[randomNFT_index[0]]\n",
    "\n",
    "print(randomNFT['token_pk'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Get NFT Info From API\n",
    "\n",
    "One NFT is chosen by random module. This NFT's info will be requested from API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#queries must be evaluated for the chosen primary key\n",
    "\n",
    "nft_info_query= \"\"\"query{\n",
    "  token(where: {pk: {_eq: \"random_pk_value\"}}) {\n",
    "    name\n",
    "    token_id\n",
    "    mime\n",
    "    supply\n",
    "    artifact_uri\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "nft_link_query=\"\"\"query{\n",
    "  token(where: {pk: {_eq: \"random_pk_value\"}}) {\n",
    "    fa {\n",
    "      token_link\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "nft_active_sale_query=\"\"\"query{\n",
    "  token(where: {pk: {_eq: \"random_pk_value\"}}) {\n",
    "  \tasks(where: {status: {_neq: \"cancelled\"}}) {\n",
    "      price\n",
    "      seller_address\n",
    "      amount_left\n",
    "      status\n",
    "      timestamp\n",
    "\t\t}\n",
    "  }\n",
    "}\"\"\"\n",
    "\n",
    "nft_creator_query=\"\"\"query{\n",
    "  token_creator(where: {token_pk: {_eq: \"random_pk_value\"}}) {\n",
    "    creator_address\n",
    "  }\n",
    "}\"\"\"\n",
    "\n",
    "\n",
    "# quick note...\n",
    "# \"tz1burnburnburnburnburnburnburjAYjjX\" is address of burn address for the burned tokens\n",
    "\n",
    "nft_collectors_query=\"\"\"query{\n",
    "  token(where: {pk: {_eq: \"random_pk_value\"}}) {\n",
    "    holders{\n",
    "      quantity\n",
    "      holder_address\n",
    "    }\n",
    "  }\n",
    "}\"\"\"\n",
    "\n",
    "#replace variable with the primary key value\n",
    "nft_info_query=nft_info_query.replace(\"random_pk_value\",str(randomNFT['token_pk']))\n",
    "nft_link_query=nft_link_query.replace(\"random_pk_value\",str(randomNFT['token_pk']))\n",
    "nft_active_sale_query=nft_active_sale_query.replace(\"random_pk_value\",str(randomNFT['token_pk']))\n",
    "nft_creator_query=nft_creator_query.replace(\"random_pk_value\",str(randomNFT['token_pk']))\n",
    "nft_collectors_query=nft_collectors_query.replace(\"random_pk_value\",str(randomNFT['token_pk']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nft_info_request = requests.post(api_endpoint, json={'query': nft_info_query})\n",
    "nft_info_request = json.loads(nft_info_request.text)\n",
    "nft_info_request = nft_info_request['data']['token']\n",
    "\n",
    "nft_link_request = requests.post(api_endpoint, json={'query': nft_link_query})\n",
    "nft_link_request = json.loads(nft_link_request.text)\n",
    "nft_link_request = nft_link_request['data']['token']\n",
    "\n",
    "nft_active_sale_request = requests.post(api_endpoint, json={'query': nft_active_sale_query})\n",
    "nft_active_sale_request = json.loads(nft_active_sale_request.text)\n",
    "nft_active_sale_request = nft_active_sale_request['data']['token']\n",
    "\n",
    "nft_creator_request = requests.post(api_endpoint, json={'query': nft_creator_query})\n",
    "nft_creator_request = json.loads(nft_creator_request.text)\n",
    "nft_creator_request = nft_creator_request['data']\n",
    "\n",
    "nft_collectors_request = requests.post(api_endpoint, json={'query': nft_collectors_query})\n",
    "nft_collectors_request = json.loads(nft_collectors_request.text)\n",
    "nft_collectors_request = nft_collectors_request['data']['token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nft_info_df=pd.DataFrame(nft_info_request)   # convert into data frame\n",
    "nft_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Generate NFT Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nft_link=nft_link_request[0]['fa']['token_link']                      # parse data\n",
    "nft_link=nft_link.replace(\":id\",str(int(nft_info_df['token_id'][0]))) # replace a part of string with the token_id to complete url\n",
    "nft_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Generate NFT Primary-Secondary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nft_active_sale_request=nft_active_sale_request[0]['asks']\n",
    "nft_active_sale_request_df=pd.DataFrame(nft_active_sale_request)\n",
    "\n",
    "if nft_active_sale_request_df.empty is True: print(\"no active sale!\")\n",
    "else: print(\"Available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Generate Creator Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nft_creator_request=nft_creator_request['token_creator']\n",
    "nft_creator_request=nft_creator_request[0]['creator_address']\n",
    "nft_creator_request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> #### TzKT API\n",
    "\n",
    "TzKT API has an endpoint to get data of wallets on tezos ecosystem. Endpoint link:\n",
    ">>>https://api.tzkt.io/\n",
    "\n",
    "In the following stage, have to match creator address with the tezos ecosystem registered name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "def artist_info(wallet_address_input):\n",
    "    account_data_url=f\"https://api.tzkt.io/v1/accounts/{wallet_address_input}\"  # tzkt.io API endpoint\n",
    "    response = requests.get(account_data_url)                                   # send request to get data\n",
    "\n",
    "    with contextlib.suppress(KeyError or json.decoder.JSONDecodeError):\n",
    "        response=response.json()\n",
    "        print(\"Owner of the wallet address is \"+response['alias'])       # printing username of account owner to see function is whether working or not\n",
    "\n",
    "    account_metadata_url=f\"https://api.tzkt.io/v1/accounts/{wallet_address_input}/metadata\"        # tzkt.io API endpoint\n",
    "    response = requests.get(account_metadata_url)                                                  # send request to get data\n",
    "\n",
    "    try:\n",
    "        response=response.json()\n",
    "        if(len(response['instagram'])):\n",
    "            print(\"https://www.instagram.com/\"+response['instagram']+\"/\")\n",
    "    except json.decoder.JSONDecodeError:pass\n",
    "    except KeyError:                                 # program gets KeyError when relevant metadata does not available for the user\n",
    "        print(\"instagram is null\")                   # print to test null case, only for validating the code\n",
    "\n",
    "\n",
    "    # get twitter username from metadata, if exists on metadata\n",
    "    try:\n",
    "        response=response.json()\n",
    "        if(len(response['twitter'])):\n",
    "            print(\"https://www.twitter.com/\"+response['twitter'])\n",
    "    except json.decoder.JSONDecodeError:pass\n",
    "    except AttributeError:\n",
    "        if(len(response['twitter'])):\n",
    "            print(\"https://www.twitter.com/\"+response['twitter'])\n",
    "    except KeyError:print(\"Twitter is null\")\n",
    "\n",
    "artist_info(nft_creator_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Feature 02*: Request Artist Info for Their **Stats** From API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Find Wallet Address of the User by *Tezos Domain* or *Twitter Address*\n",
    "\n",
    "To improve user experience, Twitter Bot should enable perform stats feature by accepting Tezos Domain as input or recognizing Twitter Address of the User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Find Wallet Address by Twitter *(if exists)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findWalletAddress_byTwitter(twitter_address):\n",
    "    creator_walletAddress_byTwitter_query=\"\"\"query{\n",
    "    tzd_domain(where: {token: {holders: {holder: {twitter: {_eq: \"twitter_address\"}}}}}) {\n",
    "        owner\n",
    "        }\n",
    "    }\"\"\"\n",
    "    evaluated_twitterAddress = f\"https://twitter.com/{str(twitter_address)}\"\n",
    "    creator_walletAddress_byTwitter_query = creator_walletAddress_byTwitter_query.replace(\"twitter_address\",evaluated_twitterAddress)\n",
    "\n",
    "    creator_twitter = requests.post(api_endpoint, json={'query': creator_walletAddress_byTwitter_query})\n",
    "    creator_twitter = json.loads(creator_twitter.text)\n",
    "    creator_twitter = creator_twitter ['data']['tzd_domain']\n",
    "    if creator_twitter != [] and creator_twitter[0]['owner'] != \"null\":\n",
    "        return str(creator_twitter[0]['owner'])\n",
    "    else:            # if query does not respond any name, then there is no wallet matched with the related twitter address\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Find Wallet Address by Tezos Domain *(if exists)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findWalletAddress_byTezDomain(tezos_domain):\n",
    "    creator_walletAddress_byDomain_query=\"\"\"query findWallet_byDomainAddress {\n",
    "    tzd_domain(where: {id: {_eq: \"tez_domain\"}}) {\n",
    "    owner\n",
    "        token {\n",
    "        holders {\n",
    "            holder {\n",
    "            twitter\n",
    "            }\n",
    "        }\n",
    "        }\n",
    "    }\n",
    "    }\"\"\"\n",
    "    creator_walletAddress_byDomain_query = creator_walletAddress_byDomain_query.replace(\"tez_domain\",tezos_domain)\n",
    "\n",
    "    creator_tezDomain = requests.post(api_endpoint, json={'query': creator_walletAddress_byDomain_query})\n",
    "    creator_tezDomain = json.loads(creator_tezDomain.text)\n",
    "    creator_tezDomain = creator_tezDomain ['data']['tzd_domain']\n",
    "    if creator_tezDomain != [] and creator_tezDomain[0]['owner'] != \"null\":\n",
    "        return str(creator_tezDomain[0]['owner'])\n",
    "    else:           # if query does not respond any name, then there is no wallet matched with the related tezos domain\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Checking the Wallet Address is Available or Not\n",
    "\n",
    "The users may enter wrong inputs, if there is no registered wallet addresses as the input then respond users with an error. Use TzKT API to check input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isWalletAddress(wallet_address):\n",
    "    account_data_url=f\"https://api.tzkt.io/v1/accounts/{wallet_address}\" # tzkt.io API endpoint\n",
    "    response = requests.get(account_data_url)\n",
    "    with contextlib.suppress(KeyError or json.decoder.JSONDecodeError):\n",
    "        response=response.json()\n",
    "        if response['type']==\"empty\":      # checking the responded data that user exists or not\n",
    "            return False\n",
    "\n",
    "\n",
    "def isAvailableWalletAddress(wallet_address):\n",
    "    if isWalletAddress(wallet_address) is False:\n",
    "        #print(\"No tezos wallet address exists with this input\")\n",
    "        return False\n",
    "    elif wallet_address is False:\n",
    "        #print(\"No tezos domain/twitter address exists for this input\")\n",
    "        return False\n",
    "    else: return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Recognizing the Input\n",
    "\n",
    "The users are enabled to ask their statistics using their tezos wallet addresses, tezos domain or Twitter addresses.\n",
    "\n",
    "To declare *input format*: The users only enter tezos wallet address/tezos domain or Twitter username. So, script must identify the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_user_input():\n",
    "    user_input=str(input(\"Please enter your tezos wallet/domain or twitter address: \"))\n",
    "    if len(user_input) == 36 and user_input.startswith(\"tz\"):\n",
    "        return isWalletAddress(user_input)\n",
    "    elif user_input.endswith(\".tez\"):\n",
    "        return findWalletAddress_byTezDomain(user_input)\n",
    "    elif user_input:\n",
    "        return findWalletAddress_byTwitter(user_input)\n",
    "    else: return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> All NFTs of a Creator\n",
    "\n",
    "Request token primary keys of a creator's all NFTs to evaluate charts for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_N=[0]\n",
    "def creator_allCreated_NFTs(wallet_address):\n",
    "    if counter_N[0]>0:global nft_pk_val\n",
    "    if counter_N[0]==0:nft_pk_val=0\n",
    "    creator_allNFTs_pk_query=\"\"\"query{\n",
    "        listing(where: {token: {creators: {creator_address: {_eq: \"wallet_address\"}, token_pk: {_gt: \"nft_pk_val\"}}}}, distinct_on: token_pk) {\n",
    "            token_pk\n",
    "            timestamp\n",
    "        }\n",
    "    }\"\"\"\n",
    "    creator_allNFTs_pk_query = creator_allNFTs_pk_query.replace(\"nft_pk_val\",str(nft_pk_val))\n",
    "    creator_allNFTs_pk_query = creator_allNFTs_pk_query.replace(\"wallet_address\",str(wallet_address))\n",
    "\n",
    "    creator_allNFTs_pk = requests.post(api_endpoint, json={'query': creator_allNFTs_pk_query})\n",
    "    creator_allNFTs_pk = json.loads(creator_allNFTs_pk.text)\n",
    "    creator_allNFTs_pk = creator_allNFTs_pk['data']['listing']\n",
    "\n",
    "    # start the mechanism if there are 500 responses\n",
    "    # otherwise, it is nonsense to wait executing all because one request is enough to get all data\n",
    "    if len(creator_allNFTs_pk)==500:\n",
    "        if counter_N[0]>0:\n",
    "            global creators_allNFTs_pk_df\n",
    "            global loop_of_allNFT_listings_df\n",
    "        if counter_N[0]==0:\n",
    "            creators_allNFTs_pk_df=pd.DataFrame()\n",
    "            loop_of_allNFT_listings_df=pd.DataFrame()\n",
    "        loop_of_allNFT_listings_df=pd.DataFrame(creator_allNFTs_pk)\n",
    "        creators_allNFTs_pk_df=pd.concat([creators_allNFTs_pk_df,loop_of_allNFT_listings_df])\n",
    "    else:creators_allNFTs_pk_df = pd.DataFrame(creator_allNFTs_pk)\n",
    "\n",
    "    # there may be multiple listings on primary, so drop duplicates\n",
    "    creators_allNFTs_pk_df = creators_allNFTs_pk_df.drop_duplicates()\n",
    "    # convert timestamp attribute data type as date\n",
    "    creators_allNFTs_pk_df['timestamp']=pd.to_datetime(creators_allNFTs_pk_df['timestamp']).dt.date\n",
    "    creators_allNFTs_pk_df=creators_allNFTs_pk_df.sort_values(by='timestamp',ascending=True)\n",
    "    # have to set index again after dropping and sorting operation\n",
    "    creators_allNFTs_pk_df = creators_allNFTs_pk_df.reset_index()\n",
    "    del creators_allNFTs_pk_df['index']\n",
    "\n",
    "    counter_N[0]=+1  # increase counter after each iteration of the function\n",
    "    if len(creators_allNFTs_pk_df)==500:\n",
    "        nft_pk_val=str(creators_allNFTs_pk_df['token_pk'][499])\n",
    "        return creator_allCreated_NFTs(wallet_address)\n",
    "    else:\n",
    "        counter_N[0]=0\n",
    "        return creators_allNFTs_pk_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Available Primary & Secondary Listings\n",
    "\n",
    "There are many productive artists on Tezos ecosystem. Showing their pieces that left on primary would be useful. This functionality will provide them a chance to track their primary and secondary pieces on the market. Additionally, they can see how many of them also sold on secondary at least one time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEVELOPER NOTE**: THIS IS THE LATEST VERSION OF THE RECURSIVE DATA REQUEST MODULE *(23.10.22, 17.44 by GMT+3)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creator_availablePrimary_NFTs(wallet_address):\n",
    "    if isAvailableWalletAddress(wallet_address) is not True:\n",
    "        print(\"You entered unregistered input. Please enter an available wallet address, tezos domain or registered twitter address with your objkt.com profile.\")\n",
    "        return          # to prevent executing rest of the function\n",
    "    if counter_N[0]>0:global nft_primaryKey_val\n",
    "    if counter_N[0]==0:nft_primaryKey_val=0\n",
    "    creator_nft_primaryNFT_info_query=\"\"\"{\n",
    "        listing(where: {seller_address: {_eq: \"wallet_address\"}, status: {_eq: \"active\"}, token: {creators: {creator_address: {_eq: \"wallet_address\"}, token_pk: {_gt: \"nft_primaryKey_val\"}}}}) {\n",
    "            token_pk\n",
    "        }\n",
    "        }\n",
    "        \"\"\"\n",
    "    creator_nft_primaryNFT_info_query = creator_nft_primaryNFT_info_query.replace(\"nft_primaryKey_val\",str(nft_primaryKey_val))\n",
    "    creator_nft_primaryNFT_info_query = creator_nft_primaryNFT_info_query.replace(\"wallet_address\",str(wallet_address))\n",
    "\n",
    "    creator_primary_nft_pk = requests.post(api_endpoint, json={'query': creator_nft_primaryNFT_info_query})\n",
    "    creator_primary_nft_pk = json.loads(creator_primary_nft_pk.text)\n",
    "    creator_primary_nft_pk = creator_primary_nft_pk['data']['listing']\n",
    "\n",
    "    # start the mechanism if there are 500 responses\n",
    "    # otherwise, it is nonsense to wait executing all because one request is enough to get all data\n",
    "    if len(creator_primary_nft_pk)==500:\n",
    "        if counter_N[0]>0:\n",
    "            global creators_availablePrimaryNFTs_pk_df\n",
    "            global loop_ofPrimary_NFT_listings_df\n",
    "        if counter_N[0]==0:\n",
    "            creators_availablePrimaryNFTs_pk_df=pd.DataFrame()\n",
    "            loop_ofPrimary_NFT_listings_df=pd.DataFrame()\n",
    "        loop_ofPrimary_NFT_listings_df=pd.DataFrame(creator_primary_nft_pk)\n",
    "        creators_availablePrimaryNFTs_pk_df=pd.concat([creators_availablePrimaryNFTs_pk_df,loop_ofPrimary_NFT_listings_df])\n",
    "\n",
    "    else:creators_availablePrimaryNFTs_pk_df = pd.DataFrame(creator_primary_nft_pk)\n",
    "\n",
    "    # there may be multiple listings on primary, so delete duplicates\n",
    "    creators_availablePrimaryNFTs_pk_df = creators_availablePrimaryNFTs_pk_df.drop_duplicates()\n",
    "    creators_availablePrimaryNFTs_pk_df = creators_availablePrimaryNFTs_pk_df.reset_index()     # have to set index again after dropping operation\n",
    "    del creators_availablePrimaryNFTs_pk_df['index']\n",
    "\n",
    "    counter_N[0]=+1\n",
    "    if len(creators_availablePrimaryNFTs_pk_df)==500:\n",
    "        nft_primaryKey_val=str(creators_availablePrimaryNFTs_pk_df['token_pk'][499])\n",
    "        return creator_availablePrimary_NFTs(wallet_address)\n",
    "    else:\n",
    "        counter_N[0]=0\n",
    "        return creators_availablePrimaryNFTs_pk_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> All Sales of an Artist for His/Her Created NFTs\n",
    "\n",
    "NFT sale history for both primary and secondary of the artists for their created pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_N=[0]\n",
    "def creator_all_NFT_sales(wallet_address):\n",
    "    if isAvailableWalletAddress(wallet_address) is not True:\n",
    "        print(\"You entered unregistered input. Please enter an available wallet address, tezos domain or registered twitter address with your objkt.com profile.\")\n",
    "        return          # to prevent executing rest of the function\n",
    "    if counter_N[0]>0:global nft_timestamp_val\n",
    "    if counter_N[0]==0:nft_timestamp_val=\"2000-01-01T00:00:00+00:00\" # initialize the timestamp value\n",
    "    creator_all_sales_query=\"\"\"query{\n",
    "    listing_sale(where: {token: {creators: {creator_address: {_eq: \"wallet_address\"}}}, timestamp: {_gt: \"nft_timestamp_val\"}}, distinct_on: timestamp) {\n",
    "        token_pk\n",
    "        timestamp\n",
    "        }\n",
    "    }\"\"\"\n",
    "    creator_all_sales_query = creator_all_sales_query.replace(\"nft_timestamp_val\",str(nft_timestamp_val))\n",
    "    creator_all_sales_query = creator_all_sales_query.replace(\"wallet_address\",str(wallet_address))\n",
    "    creator_all_sales_response= requests.post(api_endpoint, json={'query': creator_all_sales_query})\n",
    "    creator_all_sales_response = json.loads(creator_all_sales_response.text)\n",
    "    creator_all_sales_response = creator_all_sales_response['data']['listing_sale']\n",
    "\n",
    "    if counter_N[0]>0:\n",
    "        global all_NFT_sales_df\n",
    "        global loop_NFT_sales_df\n",
    "    if counter_N[0]==0:\n",
    "        all_NFT_sales_df=pd.DataFrame()\n",
    "        loop_NFT_sales_df=pd.DataFrame()\n",
    "\n",
    "    loop_NFT_sales_df = pd.DataFrame(creator_all_sales_response)\n",
    "    loop_NFT_sales_df['token_pk']=loop_NFT_sales_df['token_pk'].astype(int)\n",
    "\n",
    "    all_NFT_sales_df=pd.concat([ all_NFT_sales_df,loop_NFT_sales_df])\n",
    "    counter_N[0]+=1\n",
    "\n",
    "    # print(nft_timestamp_val)    # to check how it works\n",
    "\n",
    "    if len(creator_all_sales_response)==500:  # max retrieves are 500, if less there are no more data to response from api\n",
    "        nft_timestamp_val=str(loop_NFT_sales_df['timestamp'][499])\n",
    "        return creator_all_NFT_sales(wallet_address)\n",
    "    else:\n",
    "        counter_N[0]=0                     # reset counter in the end\n",
    "        all_NFT_sales_df=all_NFT_sales_df.reset_index()\n",
    "        del all_NFT_sales_df['index']      # also reset index, sufficient for the multiple request cases\n",
    "        return all_NFT_sales_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Primary Sales of a Creator\n",
    "\n",
    "Get Only Primary Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_N=[0]\n",
    "def creator_primary_NFT_sales(wallet_address):\n",
    "    if counter_N[0]>0:global nft_timestamp_val\n",
    "    if counter_N[0]==0:nft_timestamp_val=\"2000-01-01T00:00:00+00:00\" # initialize the timestamp value\n",
    "    creator_primary_sales_query=\"\"\"{\n",
    "    listing_sale(where: {token: {creators: {creator_address: {_eq: \"wallet_address\"}}}, timestamp: {_gt: \"nft_timestamp_val\"}, seller_address: {_eq: \"wallet_address\"}}, distinct_on: timestamp) {\n",
    "        price\n",
    "        token_pk\n",
    "        buyer_address\n",
    "        timestamp\n",
    "        }\n",
    "    }\"\"\"\n",
    "    creator_primary_sales_query = creator_primary_sales_query.replace(\"nft_timestamp_val\",str(nft_timestamp_val))\n",
    "    creator_primary_sales_query = creator_primary_sales_query.replace(\"wallet_address\",str(wallet_address))\n",
    "    creator_primary_sales_response= requests.post(api_endpoint, json={'query': creator_primary_sales_query})\n",
    "    creator_primary_sales_response = json.loads(creator_primary_sales_response.text)\n",
    "    creator_primary_sales_response = creator_primary_sales_response['data']['listing_sale']\n",
    "\n",
    "    if counter_N[0]>0:\n",
    "        global all_NFT_sales_df\n",
    "        global loop_NFT_sales_df\n",
    "    if counter_N[0]==0:\n",
    "        all_NFT_sales_df=pd.DataFrame()\n",
    "        loop_NFT_sales_df=pd.DataFrame()\n",
    "\n",
    "    loop_NFT_sales_df = pd.DataFrame(creator_primary_sales_response)\n",
    "    loop_NFT_sales_df['token_pk']=loop_NFT_sales_df['token_pk'].astype(int)\n",
    "\n",
    "    all_NFT_sales_df=pd.concat([ all_NFT_sales_df,loop_NFT_sales_df])\n",
    "    counter_N[0]+=1\n",
    "\n",
    "    if len(creator_primary_sales_response)==500:  # max retrieves are 500, if less there are no more data to response from api\n",
    "        nft_timestamp_val=str(loop_NFT_sales_df['timestamp'][499])\n",
    "        return creator_primary_NFT_sales(wallet_address)\n",
    "    else:\n",
    "        counter_N[0]=0                # reset counter in the end\n",
    "        return all_NFT_sales_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Handling Data Frame\n",
    "\n",
    "* Manipulate Price Value for Exact Amounts\n",
    "* Handle Timestamp Attribute\n",
    "* Calculate Income Over Months\n",
    "* Append Non-existing Months for Accurate Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the first mint date of a creator and return as year-month format\n",
    "# will be using on multiple functions, creator_primary_sales_df() as well\n",
    "def find_first_minting_date(wallet_address):\n",
    "    firstMintDate_ofCreator=creator_allCreated_NFTs(wallet_address)        # assign data frame of all NFTs of the creator\n",
    "    firstMintDate_ofCreator=firstMintDate_ofCreator.loc[0]['timestamp']    # then assign first NFT's time to the variable\n",
    "    firstMintDate_ofCreator=firstMintDate_ofCreator.strftime('%Y-%m')      # drop day from the date\n",
    "    return firstMintDate_ofCreator\n",
    "\n",
    "# spotting the latest's date in year-month format\n",
    "def find_last_sale_date(wallet_address):\n",
    "    last_sale_date=creator_all_NFT_sales(wallet_address)\n",
    "    last_sale_date=last_sale_date.apply(pd.to_datetime)\n",
    "    last_sale_date=last_sale_date.loc[len(last_sale_date)-1]['timestamp']\n",
    "    last_sale_date=last_sale_date.strftime('%Y-%m')\n",
    "    return last_sale_date\n",
    "\n",
    "def creator_primary_sales_df(wallet_address):\n",
    "    creator_primary_sales_dataFrame=creator_primary_NFT_sales(wallet_address)\n",
    "\n",
    "    # manipulating price column to calculate exact value [as tezos] of a token\n",
    "    # dividing to 10^6\n",
    "    creator_primary_sales_dataFrame['price']=pd.to_numeric(creator_primary_sales_dataFrame['price'],downcast=\"float\")\n",
    "    creator_primary_sales_dataFrame['price']=creator_primary_sales_dataFrame['price']/1000000\n",
    "    # manipulate timestamp attribute data type as date\n",
    "    creator_primary_sales_dataFrame['timestamp']=pd.to_datetime(creator_primary_sales_dataFrame['timestamp']).dt.date\n",
    "    # convert all days to 1 for grouping by year-month pair\n",
    "    creator_primary_sales_dataFrame['timestamp']=creator_primary_sales_dataFrame['timestamp'].apply(lambda dt: dt.replace(day=1))\n",
    "\n",
    "    creator_primary_sales_dataFrame = creator_primary_sales_dataFrame.groupby('timestamp').sum()\n",
    "    del creator_primary_sales_dataFrame['token_pk']\n",
    "\n",
    "    creator_primary_sales_dataFrame = creator_primary_sales_dataFrame.reset_index()           # convert to data frame from pivot table\n",
    "    creator_primary_sales_dataFrame['timestamp'] = creator_primary_sales_dataFrame['timestamp'].apply(lambda x: x.strftime('%Y-%m'))\n",
    "    creator_primary_sales_dataFrame = creator_primary_sales_dataFrame.set_index('timestamp')  # then set date as index\n",
    "\n",
    "    firstMintDate_ofCreator=find_first_minting_date(wallet_address)\n",
    "    lastSaleDate_ofCreator=find_last_sale_date(wallet_address)\n",
    "    def date_range_df(firstMintDate_ofCreator):\n",
    "        # define a range to fill missing months -if exists- in data frame\n",
    "        sale_date_range = pd.date_range(\n",
    "                            start=firstMintDate_ofCreator,         # using the variable for calculating minting range\n",
    "                            end=lastSaleDate_ofCreator).to_period('m')\n",
    "        # create a data frame to save all of the months in the range\n",
    "        sale_date_range=pd.DataFrame(sale_date_range)\n",
    "        sale_date_range=sale_date_range.drop_duplicates(keep=\"first\")\n",
    "        sale_date_range['price']= 0\n",
    "        sale_date_range=sale_date_range.rename(columns={0:'timestamp'})\n",
    "        sale_date_range['timestamp'] = sale_date_range['timestamp'].apply(lambda x: x.strftime('%Y-%m'))\n",
    "        sale_date_range=sale_date_range.groupby('timestamp').sum()\n",
    "        return sale_date_range\n",
    "\n",
    "    creator_primary_sales=date_range_df(firstMintDate_ofCreator)    # assign the data frame returned from the function\n",
    "\n",
    "    creator_primary_sales=creator_primary_sales.reset_index()       # then reset index before mapping\n",
    "    creator_primary_sales_dataFrame=creator_primary_sales_dataFrame.reset_index()\n",
    "\n",
    "    # use mapping to fill new data frame with values, keep NaN non-existing months on actual data frame\n",
    "    creator_primary_sales['price']=creator_primary_sales['timestamp'].map(creator_primary_sales_dataFrame.set_index('timestamp')['price'])\n",
    "    creator_primary_sales=creator_primary_sales.fillna(0)\n",
    "\n",
    "    return creator_primary_sales.set_index('timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Count Sales by Editions Over Months [Only Primary]\n",
    "\n",
    "Counting number of sales by editions will enable NFT creators to determine amount of editions for next mintings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creator_primarySales_byEditions_df(wallet_address):\n",
    "    creator_primary_sales_dataFrame=creator_primary_NFT_sales(wallet_address)\n",
    "\n",
    "    # deleting unnecessary attributes from data frame\n",
    "    del creator_primary_sales_dataFrame['buyer_address']\n",
    "    del creator_primary_sales_dataFrame['price']\n",
    "\n",
    "    # manipulate timestamp attribute data type as date\n",
    "    creator_primary_sales_dataFrame['timestamp']=pd.to_datetime(creator_primary_sales_dataFrame['timestamp']).dt.date\n",
    "    creator_primary_sales_dataFrame['timestamp']=creator_primary_sales_dataFrame['timestamp'].apply(lambda dt: dt.replace(day=1))\n",
    "    creator_primary_sales_dataFrame['timestamp']=creator_primary_sales_dataFrame['timestamp'].apply(lambda x: x.strftime('%Y-%m'))\n",
    "\n",
    "    creator_primary_sales_dataFrame = creator_primary_sales_dataFrame.groupby('timestamp').count()\n",
    "\n",
    "    # implementing the same algorithm with the function above to fill missing months, in case they exist\n",
    "    firstMintDate_ofCreator=creator_allCreated_NFTs(wallet_address)\n",
    "    firstMintDate_ofCreator=firstMintDate_ofCreator.loc[0]['timestamp']\n",
    "    firstMintDate_ofCreator=firstMintDate_ofCreator.strftime('%Y-%m')\n",
    "\n",
    "    def date_range_df(firstMintDate_ofCreator):\n",
    "        sale_date_range = pd.date_range(\n",
    "                            start=firstMintDate_ofCreator,\n",
    "                            end=creator_primary_sales_dataFrame.index[len(creator_primary_sales_dataFrame)-1]).to_period('m')\n",
    "        sale_date_range=pd.DataFrame(sale_date_range)\n",
    "        sale_date_range=sale_date_range.drop_duplicates(keep=\"first\")\n",
    "        sale_date_range['token_pk']= 0\n",
    "        sale_date_range=sale_date_range.rename(columns={0:'timestamp'})\n",
    "        sale_date_range['timestamp'] = sale_date_range['timestamp'].apply(lambda x: x.strftime('%Y-%m'))\n",
    "        sale_date_range=sale_date_range.groupby('timestamp').sum()\n",
    "        return sale_date_range\n",
    "\n",
    "    creator_primary_sales=date_range_df(firstMintDate_ofCreator)\n",
    "\n",
    "    creator_primary_sales=creator_primary_sales.reset_index()\n",
    "    creator_primary_sales_dataFrame=creator_primary_sales_dataFrame.reset_index()\n",
    "\n",
    "    creator_primary_sales['token_pk']=creator_primary_sales['timestamp'].map(creator_primary_sales_dataFrame.set_index('timestamp')['token_pk'])\n",
    "    creator_primary_sales=creator_primary_sales.fillna(0)\n",
    "\n",
    "    creator_primary_sales['token_pk']=creator_primary_sales['token_pk'].astype(int)\n",
    "    creator_primary_sales=creator_primary_sales.rename(columns={'token_pk':'sold_editions'})\n",
    "\n",
    "    return creator_primary_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Visualize Primary Sale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualized_creator_primary_sales(wallet_address):\n",
    "    if isAvailableWalletAddress(wallet_address) is not True:\n",
    "        print(\"You entered unregistered input. Please enter an available wallet address, tezos domain or registered twitter address with your objkt.com profile.\")\n",
    "        return         # to prevent executing rest of the function\n",
    "    dataFrame_toPlot=creator_primary_sales_df(wallet_address)\n",
    "    # use pandas data frame plot to visualize the data\n",
    "    dataFrame_toPlot.plot(kind='bar',title=f\"Revenue of the Artist ({wallet_address}) on Primary Market by Month\",xlabel=\"Month\",ylabel=\"Revenue (by Tezos)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Secondary Sales of the Artist with Royalties Income\n",
    "\n",
    "* Retrieve Secondary Sales from API\n",
    "* Get Royalties of Tokens\n",
    "* Manipulate Timestamp\n",
    "* Shape with Same Format as Primary Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two functions that gathers secondary sales data frame:\n",
    "\n",
    "* **creator_secondary_NFT_sales_tokens()** -collects *sale price, token primary key, sale date* and *collector wallet address* from API\n",
    "* **creator_secondary_NFT_sales_royalties()** -collects *artist royalty* of the sold token from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creator_secondary_NFT_sales_tokens(wallet_address):\n",
    "    if counter_N[0]>0:global nft_timestamp_val\n",
    "    if counter_N[0]==0:nft_timestamp_val=\"2000-01-01T00:00:00+00:00\" # initialize the timestamp value\n",
    "    creator_secondary_sales_query=\"\"\"{\n",
    "    listing_sale(where: {token: {creators: {creator_address: {_eq: \"wallet_address\"}}}, timestamp: {_gt: \"nft_timestamp_val\"}, seller_address: {_neq: \"wallet_address\"}}, distinct_on: timestamp) {\n",
    "        price\n",
    "        token_pk\n",
    "        buyer_address\n",
    "        timestamp\n",
    "        }\n",
    "    }\"\"\"\n",
    "\n",
    "    def send_request_sales(query_input):                 # the function is too complicated so wanted to minimize using a function\n",
    "        query_input = query_input.replace(\"nft_timestamp_val\",str(nft_timestamp_val))\n",
    "        query_input = query_input.replace(\"wallet_address\",str(wallet_address))\n",
    "\n",
    "        global response          # avoid UnboundLocal Error\n",
    "        response = requests.post(api_endpoint, json={'query': query_input})\n",
    "        response = json.loads(response.text)\n",
    "        response = response['data']['listing_sale']\n",
    "        return response\n",
    "\n",
    "    creator_secondary_sales_response=send_request_sales(creator_secondary_sales_query)\n",
    "\n",
    "    if counter_N[0]>0:\n",
    "        global all_secondaryNFT_sales_df\n",
    "        global loop_secondaryNFT_sales_df\n",
    "    if counter_N[0]==0:\n",
    "        all_secondaryNFT_sales_df=pd.DataFrame()\n",
    "        loop_secondaryNFT_sales_df=pd.DataFrame()\n",
    "\n",
    "    loop_secondaryNFT_sales_df = pd.DataFrame(creator_secondary_sales_response)\n",
    "    loop_secondaryNFT_sales_df['token_pk']=loop_secondaryNFT_sales_df['token_pk'].astype(int)\n",
    "    loop_secondaryNFT_sales_df['price']=loop_secondaryNFT_sales_df['price'].astype(int)\n",
    "    # loop data frame saves the data for each iteration of the recursive algorithm, it is temporary data source...\n",
    "    # data frame starts with \"all\" includes all of the retrieved data, it is permanent data frame that loop data frame transports data\n",
    "    all_secondaryNFT_sales_df=pd.concat([ all_secondaryNFT_sales_df,loop_secondaryNFT_sales_df])\n",
    "\n",
    "    counter_N[0]+=1\n",
    "    if len(creator_secondary_sales_response)==500:  # max retrieves are 500, if less there are no more data to response from api\n",
    "        nft_timestamp_val=str(loop_secondaryNFT_sales_df['timestamp'][499])\n",
    "        return creator_secondary_NFT_sales_tokens(wallet_address)\n",
    "    else:\n",
    "        counter_N[0]=0\n",
    "        return all_secondaryNFT_sales_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creator_secondary_NFT_sales_royalties(wallet_address):\n",
    "    if counter_N[0]>0:global nft_timestamp_val\n",
    "    if counter_N[0]==0:nft_timestamp_val=\"2000-01-01T00:00:00+00:00\" # initialize the timestamp value\n",
    "    creator_secondary_sales_royalties_query=\"\"\"{\n",
    "    listing_sale(where: {token: {creators: {creator_address: {_eq: \"wallet_address\"}}}, timestamp: {_gt: \"nft_timestamp_val\"}, seller_address: {_neq: \"wallet_address\"}}, distinct_on: timestamp) {\n",
    "        token {\n",
    "        royalties {\n",
    "            amount\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    }\"\"\"\n",
    "    def send_request(query_input):                 # the function is too complicated so wanted to minimize using a function\n",
    "        query_input = query_input.replace(\"nft_timestamp_val\",str(nft_timestamp_val))\n",
    "        query_input = query_input.replace(\"wallet_address\",str(wallet_address))\n",
    "\n",
    "        global response          # avoid UnboundLocal Error\n",
    "        response = requests.post(api_endpoint, json={'query': query_input})\n",
    "        response = json.loads(response.text)\n",
    "        response = response['data']['listing_sale']\n",
    "        return response\n",
    "\n",
    "    response=send_request(creator_secondary_sales_royalties_query)\n",
    "\n",
    "    if counter_N[0]>0:\n",
    "        global all_secondaryNFT_sales_df\n",
    "        global loop_secondaryNFT_sales_df\n",
    "    if counter_N[0]==0:\n",
    "        all_secondaryNFT_sales_df=pd.DataFrame()\n",
    "        loop_secondaryNFT_sales_df=pd.DataFrame()\n",
    "\n",
    "    loop_secondaryNFT_sales_df = pd.DataFrame(response)\n",
    "    # loop data frame saves the data for each iteration of the recursive algorithm, it is temporary data source...\n",
    "    # data frame starts with \"all\" includes all of the retrieved data, it is permanent data frame that loop data frame transports data\n",
    "    all_secondaryNFT_sales_df=pd.concat([ all_secondaryNFT_sales_df,loop_secondaryNFT_sales_df])\n",
    "\n",
    "    def clean_data(df):\n",
    "        df['token'] = df['token'].astype(str)\n",
    "        df['token'] = df['token'].str.replace(r\"[a-zA-Z]\",'')\n",
    "        df['token'] = df['token'].str.replace(f'[{string.punctuation}]', '')\n",
    "        # avoid errors in collaboration cases (in collabs there are multiple royalties. need only 1st)\n",
    "        df['token'] = [x[:5] for x in df['token']]\n",
    "        # available to convert numerical data type after necessary operations are implemented\n",
    "        df['token'] = df['token'].astype(int)\n",
    "        df['token'] = df['token']/10    # manipulate into exact value\n",
    "        return df\n",
    "\n",
    "    clean_data(all_secondaryNFT_sales_df)\n",
    "\n",
    "    counter_N[0]+=1\n",
    "    if len(response)==500:  # max retrieves are 500, if less there are no more data to response from api\n",
    "        nft_timestamp_val=str(loop_secondaryNFT_sales_df['timestamp'][499])\n",
    "        return creator_secondary_NFT_sales_royalties(wallet_address)\n",
    "    else:\n",
    "        counter_N[0]=0\n",
    "        return all_secondaryNFT_sales_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creator_secondary_NFT_sales(wallet_address):\n",
    "    royalties_df=creator_secondary_NFT_sales_royalties(wallet_address)\n",
    "    tokens_df=creator_secondary_NFT_sales_tokens(wallet_address)\n",
    "\n",
    "    secondary_sales_df = pd.concat([tokens_df,royalties_df], axis=1, join=\"inner\")\n",
    "    secondary_sales_df['artist_income'] = \"\"                                        # create a new column to save calculated value\n",
    "    secondary_sales_df = secondary_sales_df.rename(columns={'token':'royalties'})   # rename to understand purpose of the attribute better\n",
    "    secondary_sales_df['artist_income'] = (secondary_sales_df[[\"price\", \"royalties\"]].product(axis=1))\n",
    "    secondary_sales_df['artist_income'] = secondary_sales_df['artist_income']/100000000\n",
    "\n",
    "    return secondary_sales_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creator_secondary_sales_df(wallet_address):\n",
    "    secondary_sales_df=creator_secondary_NFT_sales(wallet_address)\n",
    "    secondary_sales_df=secondary_sales_df[['timestamp','artist_income']]    # keep only these two columns\n",
    "\n",
    "    # manipulate timestamp attribute data type as date\n",
    "    secondary_sales_df['timestamp'] = pd.to_datetime(secondary_sales_df['timestamp']).dt.date\n",
    "    secondary_sales_df['timestamp'] = secondary_sales_df['timestamp'].apply(lambda dt: dt.replace(day=1))\n",
    "    secondary_sales_df['timestamp'] = secondary_sales_df['timestamp'].apply(lambda x: x.strftime('%Y-%m'))\n",
    "    secondary_sales_df = secondary_sales_df.groupby('timestamp').sum()\n",
    "\n",
    "    firstMintDate_ofCreator=find_first_minting_date(wallet_address)\n",
    "    lastSaleDate_ofCreator=find_last_sale_date(wallet_address)\n",
    "    def date_range_df(firstMintDate_ofCreator):\n",
    "        sale_date_range = pd.date_range(\n",
    "                            start=firstMintDate_ofCreator,\n",
    "                            end=lastSaleDate_ofCreator).to_period('m')\n",
    "        sale_date_range=pd.DataFrame(sale_date_range)\n",
    "        sale_date_range=sale_date_range.drop_duplicates(keep=\"first\")\n",
    "        sale_date_range['artist_income']= 0\n",
    "        sale_date_range=sale_date_range.rename(columns={0:'timestamp'})\n",
    "        sale_date_range['timestamp'] = sale_date_range['timestamp'].apply(lambda x: x.strftime('%Y-%m'))\n",
    "        sale_date_range=sale_date_range.groupby('timestamp').sum()\n",
    "        return sale_date_range\n",
    "    creator_secondary_sales=date_range_df(firstMintDate_ofCreator)    # assign the data frame returned from the function\n",
    "\n",
    "    creator_secondary_sales = creator_secondary_sales.reset_index()   # then reset index before mapping\n",
    "    secondary_sales_df = secondary_sales_df.reset_index()\n",
    "\n",
    "    # use mapping to fill new data frame with values, keep NaN non-existing months on actual data frame\n",
    "    creator_secondary_sales['artist_income'] = creator_secondary_sales['timestamp'].map(secondary_sales_df.set_index('timestamp')['artist_income'])\n",
    "    creator_secondary_sales = creator_secondary_sales.fillna(0)\n",
    "\n",
    "    return creator_secondary_sales.set_index('timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Merge Primary & Secondary Sales Data Frames\n",
    "\n",
    "Merge two data frames that outputs of these two functions:\n",
    "* creator_primary_sales_df()\n",
    "* creator_secondary_sales_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creator_all_sales_df(wallet_address):\n",
    "    primary_df = creator_primary_sales_df(wallet_address)\n",
    "    secondary_df = creator_secondary_sales_df(wallet_address)\n",
    "\n",
    "    primary_df=primary_df.rename(columns={'price':'primary_income'})\n",
    "    secondary_df=secondary_df.rename(columns={'artist_income':'secondary_income'})\n",
    "\n",
    "    return pd.concat([primary_df,secondary_df],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next part is the prepare works for upcoming user story\n",
    "\n",
    "*Just a sketch notes for a development*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creator_secondary_NFT_sales_count(wallet_address):\n",
    "    secondarySales_df=creator_secondary_NFT_sales(wallet_address)\n",
    "    secondarySales_df['token_pk']=secondarySales_df['token_pk'].drop_duplicates(keep=\"first\")\n",
    "    secondarySales_df=secondarySales_df.dropna()\n",
    "    return len(secondarySales_df)\n",
    "\n",
    "def numerical_creator_primarySecondary_Stats(wallet_address):\n",
    "    number_ofAvailablePrimaryNFTs_ofCreator=creator_availablePrimary_NFTs(wallet_address)\n",
    "    number_ofAvailablePrimaryNFTs_ofCreator=len(number_ofAvailablePrimaryNFTs_ofCreator)\n",
    "    number_ofSoldSecondaryNFTs_ofCreator=creator_secondary_NFT_sales_count(wallet_address)\n",
    "    # using the number of all created NFTs of a creator to perform calculations for unsold NFTs on secondary\n",
    "    number_ofAllCreatedNFTs_ofCreator=creator_allCreated_NFTs(wallet_address)\n",
    "    number_ofUnsoldSecondaryNFTs_ofCreator=len(number_ofAllCreatedNFTs_ofCreator)-number_ofAvailablePrimaryNFTs_ofCreator-number_ofSoldSecondaryNFTs_ofCreator\n",
    "    return number_ofAvailablePrimaryNFTs_ofCreator,number_ofSoldSecondaryNFTs_ofCreator,number_ofUnsoldSecondaryNFTs_ofCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualized_creator_primarySecondary_Stats(wallet_address):\n",
    "    creator_PrimarySecondary_Stats=numerical_creator_primarySecondary_Stats(wallet_address)\n",
    "    creator_PrimarySecondary_Stats=plt.pie(creator_PrimarySecondary_Stats,shadow=True,labels=['At least one Sale on Secondary',\n",
    "                                                        'Available on Primary','Available on Secondary'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa3b654c9bd7dd0d2898fbffb0b4bba72a32af8626a103ba2d5323634cd89e05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
